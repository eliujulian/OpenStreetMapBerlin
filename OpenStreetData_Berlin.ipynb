{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetData Case Study for the Metro Area of Berlin, Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Area\n",
    "\n",
    "Berlin Metro Area, Germany. Berlin was choosen, since it is my hometown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "I've downloaded the available data from https://mapzen.com/data/metro-extracts/ (May 2nd, 2016), extracted nodes and ways and imported the data into a sqlite database (See file data_preparation.py, database schama see schema.txt). Some unknown characters in usernames (kyrillic) lead to problem extracting the 'nodes' and 'ways' from the OSM File. SQL import errors lead to a not complete database. \n",
    "\n",
    "Therefore, the count of rows was checked against the csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Warning: Takes some time with the big csv files.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_nodes = pd.DataFrame.from_csv('nodes.csv')\n",
    "df_nodes_tags = pd.DataFrame.from_csv('nodes_tags.csv')\n",
    "df_ways = pd.DataFrame.from_csv('ways.csv')\n",
    "df_ways_tags = pd.DataFrame.from_csv('ways_tags.csv')\n",
    "df_ways_nodes = pd.DataFrame.from_csv('ways_nodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of rows in csv files\n",
      "nodes:  10460000\n",
      "nodes_tags:  3658234\n",
      "ways:  1596861\n",
      "ways_tags:  4191676\n",
      "ways_nodes:  13362536\n"
     ]
    }
   ],
   "source": [
    "print(\"Count of rows in csv files\")\n",
    "print(\"nodes: \", len(df_nodes.index.values))\n",
    "print(\"nodes_tags: \", len(df_nodes_tags.index.values))\n",
    "print(\"ways: \", len(df_ways.index.values))\n",
    "print(\"ways_tags: \", len(df_ways_tags.index.values))\n",
    "print(\"ways_nodes: \", len(df_ways_nodes.index.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of rows in database:\n",
    "\n",
    "    SELECT Count(*) FROM nodes;\n",
    "    > 10,460,000\n",
    "    \n",
    "    SELECT Count(*) FROM nodes_tags;\n",
    "    > 3,658,235\n",
    "    \n",
    "    SELECT Count(*) FROM ways;\n",
    "    > 1,596,861\n",
    "    \n",
    "    SELECT Count(*) FROM ways_tags;\n",
    "    > 4,191,677\n",
    "    \n",
    "    SELECT Count(*) FROM ways_nodes;\n",
    "    > 13,362,537\n",
    "\n",
    "The tables nodes_tags, ways_tags and ways_nodes are one row longer. A manual inspection revealed that the column names were added as a data row. These rows were removed manualy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, since nodes_tags and nodes_ways are sub to nodes and ways, ids from the tags file should allways refer to a valid id in the nodes or ways file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(set(df_nodes_tags.index.values) <= set(df_nodes.index.values))\n",
    "print(set(df_ways_tags.index.values) <= set(df_ways.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('data1.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "nodes_set = set([n[0] for n in c.execute(\"SELECT id FROM nodes\").fetchall()])\n",
    "nodes_tags_set = set([n[0] for n in c.execute(\"SELECT id FROM nodes_tags\").fetchall()])\n",
    "ways_set = set([n[0] for n in c.execute(\"SELECT id FROM ways\").fetchall()])\n",
    "ways_tags_set = set([n[0] for n in c.execute(\"SELECT id FROM ways_tags\").fetchall()])\n",
    "\n",
    "print(nodes_tags_set <= nodes_set)\n",
    "print(ways_tags_set <= ways_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Sizes\n",
    "\n",
    "* 'berlin.osm':    2.29 GB (uncompressed)\n",
    "* 'nodes.csv':      833 MB\n",
    "* 'nodes_tags.csv': 131 MB\n",
    "* 'ways.csv':        93 MB\n",
    "* 'ways_nodes.csv': 316 MB\n",
    "* 'ways_tags.csv':  140 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the data\n",
    "\n",
    "While evaluating the data the following problems were encountered:\n",
    "\n",
    "* (nodes table) Columns lat and lon use different precision. \n",
    "* (nodes_tags table) Column key has values that are probably inconsistencies, like 'addr' and 'address' or 'abbr' and 'abrevation'\n",
    "* (nodes_tags table) The key 'fixme', 'FIXME' and 'TODO' was found.\n",
    "* (ways_tags table) The column value holds unexpected values for column key filtered for maxspeed. 250 is unlikely (39 times) as well as 210 or 190. Also the max limit 30 seems to be encoded in various different ways (30, DE:zone30, DE:zone:30, DE:30, PL:zone30, DE:zone(:30), zone30)\n",
    "* (ways_tags table) The column value holds unexpected values for the column key filtered by postcode. Postcodes are five digits starting (in Berlin) with a 1. '66-470' (1,632 times), '74-500' (1,486 times) and '74-505' (938 times) do not match this criteria. There are codes starting with a '0' (mostly area around Berlin) and one code is '39264' (a place called Deetz and quite a bit away from Berlin)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nodes table : columns lat and lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nodes_tags table:  Inconsistent keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nodes_tags table: fixme and todo keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ways_tags table: maxspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ways_tags table: postcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the contributors\n",
    "\n",
    "### Number of unique contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7903\n"
     ]
    }
   ],
   "source": [
    "print(c.execute(\"SELECT Count(*) FROM (SELECT uid FROM nodes UNION SELECT uid FROM ways) tmp;\").fetchall()[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 15 contributors by count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atpl_pilot 2,378,801\n",
      "jacobbraeutigam 574,371\n",
      "r-michael 337,015\n",
      "streckenkundler 335,778\n",
      "anbr 329,417\n",
      "atpl_pilot 312,716\n",
      "WegefanHB 281,135\n",
      "Bot45715 242,853\n",
      "Konrad Aust 166,110\n",
      "toaster 156,494\n",
      "Elwood 151,421\n",
      "g0ldfish 145,945\n",
      "geozeisig 120,498\n",
      "Polarbear 116,260\n",
      "Randbewohner 102,982\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "statement = \"\"\"\n",
    "SELECT user, COUNT(*) FROM nodes\n",
    "  GROUP BY user\n",
    "UNION ALL\n",
    "SELECT user, COUNT(*) FROM ways\n",
    "  GROUP BY user\n",
    "ORDER BY COUNT(*) DESC\n",
    "LIMIT 15;\n",
    "\"\"\"\n",
    "\n",
    "for n in c.execute(statement).fetchall():\n",
    "    print(n[0], \"{:,}\".format(n[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 15 longest active contributors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anemities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster of italien places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas for Improvement\n",
    "\n",
    "The data for Berlin is generally on a high level. Common standards are partly missing for values like maxspeed on ways. It should be possible to work on this in a programmatical way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Berlin is big and cleaning up all the \"fixme\" and other open ends is a lifetime job. The data is generally considering the size quite good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
