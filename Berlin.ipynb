{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetData Case Study for the Metro Area of Berlin, Germany\n",
    "\n",
    "## 1. Data Source and Data Wrangling\n",
    "\n",
    "### 1.1 Map Area  \n",
    "\n",
    "Berlin Metro Area, Germany.\n",
    "\n",
    "### 1.2 Data Source\n",
    "\n",
    "I've downloaded the available data from https://mapzen.com/data/metro-extracts/ (May 2nd, 2016), extracted nodes and ways and imported the data into a sqlite database (See file data_preparation.py, database schama see schema.txt). \n",
    "\n",
    "### 1.3 Data Wrangling\n",
    "\n",
    "The data was directly importet into two SQLite Databasese (data_dirty.db and data_clean.db). SQLite Capabilities were more convinient to inspect and clean the dataset since the sice of the csv files made working with them dificult.\n",
    "\n",
    "I performed checks on the database to ensure complete integration of all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pyhton 3.5\n",
    "\n",
    "import sqlite3\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "conn_dirty = sqlite3.connect('data_dirty.db')\n",
    "c_dirty = conn_dirty.cursor()\n",
    "conn_clean = sqlite3.connect('data_clean.db')\n",
    "c_clean = conn_clean.cursor()\n",
    "\n",
    "\n",
    "def time_from_timestamp(timestamp_input):\n",
    "    # Helper to get a datetime object from the sql timestamp fields.\n",
    "    # Precision is limited days.\n",
    "    year = int(timestamp_input[:4])\n",
    "    month = int(timestamp_input[5:7])\n",
    "    day = int(timestamp_input[8:10])\n",
    "    return datetime.datetime(year, month, day)\n",
    "\n",
    "def formatnum(num):\n",
    "    # Helper for printing number with the comma.\n",
    "    return \"{:,}\".format(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Warning: Takes some time with the big csv files.\n",
    "\n",
    "df_nodes = pd.DataFrame.from_csv('nodes.csv')\n",
    "df_nodes_tags = pd.DataFrame.from_csv('nodes_tags.csv')\n",
    "df_ways = pd.DataFrame.from_csv('ways.csv')\n",
    "df_ways_tags = pd.DataFrame.from_csv('ways_tags.csv')\n",
    "df_ways_nodes = pd.DataFrame.from_csv('ways_nodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes:       10,460,000\n",
      "nodes_tags:   3,658,234\n",
      "ways:         1,596,861\n",
      "ways_tags:    4,191,676\n",
      "ways_nodes:  13,362,536\n"
     ]
    }
   ],
   "source": [
    "print(\"nodes:      \", formatnum(len(df_nodes.index.values)))\n",
    "print(\"nodes_tags:  \", formatnum(len(df_nodes_tags.index.values)))\n",
    "print(\"ways:        \", formatnum(len(df_ways.index.values)))\n",
    "print(\"ways_tags:   \", formatnum(len(df_ways_tags.index.values)))\n",
    "print(\"ways_nodes: \", formatnum(len(df_ways_nodes.index.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of rows in database dirty\n",
      "nodes:       10,460,000\n",
      "nodes_tags:   3,658,234\n",
      "ways:         1,596,861\n",
      "ways_tags:    4,191,676\n",
      "ways_nodes:  13,362,536\n"
     ]
    }
   ],
   "source": [
    "print(\"Count of rows in database dirty\")\n",
    "print(\"nodes:      \", formatnum(c_dirty.execute(\"SELECT Count(*) FROM nodes\").fetchall()[0][0]))\n",
    "print(\"nodes_tags:  \", formatnum(c_dirty.execute(\"SELECT Count(*) FROM nodes_tags\").fetchall()[0][0]))\n",
    "print(\"ways:        \", formatnum(c_dirty.execute(\"SELECT Count(*) FROM ways\").fetchall()[0][0]))\n",
    "print(\"ways_tags:   \", formatnum(c_dirty.execute(\"SELECT Count(*) FROM ways_tags\").fetchall()[0][0]))\n",
    "print(\"ways_nodes: \", formatnum(c_dirty.execute(\"SELECT Count(*) FROM ways_nodes\").fetchall()[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, since nodes_tags and nodes_ways are sub to nodes and ways, ids from the tags file should allways refer to a valid id in the nodes or ways file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(set(df_nodes_tags.index.values) <= set(df_nodes.index.values))\n",
    "print(set(df_ways_tags.index.values) <= set(df_ways.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "nodes_set = set([n[0] for n in c_dirty.execute(\"SELECT id FROM nodes\").fetchall()])\n",
    "nodes_tags_set = set([n[0] for n in c_dirty.execute(\"SELECT id FROM nodes_tags\").fetchall()])\n",
    "ways_set = set([n[0] for n in c_dirty.execute(\"SELECT id FROM ways\").fetchall()])\n",
    "ways_tags_set = set([n[0] for n in c_dirty.execute(\"SELECT id FROM ways_tags\").fetchall()])\n",
    "\n",
    "print(nodes_tags_set <= nodes_set)\n",
    "print(ways_tags_set <= ways_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 4 File Sizes\n",
    "\n",
    "* 'berlin.osm':    2.29 GB (uncompressed)\n",
    "* 'nodes.csv':      833 MB\n",
    "* 'nodes_tags.csv': 131 MB\n",
    "* 'ways.csv':        93 MB\n",
    "* 'ways_nodes.csv': 316 MB\n",
    "* 'ways_tags.csv':  140 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Audit\n",
    "\n",
    "While evaluating the data the following problems were encountered:\n",
    "\n",
    "* (nodes table) Columns lat and lon use different precision. \n",
    "* (nodes_tags table) Column key has values that are inconsitent like 'addr' and 'address' or 'abbr' and 'abrevation'\n",
    "* (nodes_tags table) The key 'fixme', 'FIXME' and 'TODO' was found.\n",
    "* (ways_tags table) The column value holds unexpected values for column key filtered for maxspeed. 250 is unlikely (39 times) as well as 210 or 190. Also the max limit 30 seems to be encoded in various different ways (30, DE:zone30, DE:zone:30, DE:30, PL:zone30, DE:zone(:30), zone30)\n",
    "* (ways_tags table) The column value holds unexpected values for the column key filtered by postcode. Postcodes are five digits starting (in Berlin) between 10115 and 14199. '66-470' (1,632 times), '74-500' (1,486 times) and '74-505' (938 times) do not match this criteria. There are codes starting with a '0' (mostly area around Berlin) and one code is '39264'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 nodes table : columns lat and lon\n",
    "\n",
    "An evaluation found, that there are 20 rows in the nodes table, that have a precision of 3 places or less after the dot. This means the precisions is somewhere in the range of about +/- 100 Meters .Therefore, for most uses this would be considered not accurate enough. Most accuracy ist registered 4 places better (7 digits after the dot). Examining the relating nodes_tags and ways_tags for these rows revelead that most rows represented an real world object that had a big 'footprint' and therefore can not be pinpointed to a very precise location. Five rows are villages and eleven are lakes. For the rest we might not rule out the possibilty that just zeros were removed at the end and that the lon and lat actually are the most precise coordinates. No cleaning was applied to lat and lon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 nodes_tags table:  Inconsistent keys\n",
    "\n",
    "An evaluation of several who share the same beginning of the string showed that some have the same meaning  while others don't. 'art' and 'artist' have different meaning, 'addr' and 'address' do not. The inconsistencies would have to be cleaned manually. Some keys were also formated inconsistent through the use of capital letters (\"fixme\" and \"FIXME\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 nodes_tags table: fixme and todo keys\n",
    "\n",
    "'fixme' keys were found. An inspection revealed only problems that coud not be solved programatical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 ways_tags table: maxspeed\n",
    "\n",
    "The evaluation of the ways_tags table showed that the meaning of the key \"maxspeed\" is ambigious. I sometimes refers to the speedlimit imposed by law (eg. 30, 50, 100) and sometimes to the technical maxspeed as comissioned (230). Both have a different meaning and should not be mixed into one key. The type of the value also differed often between plain numbers (30, 50, ...), number with a unit or sometimes a long text with a description.\n",
    "\n",
    "The evaluation also showed that the key to designate a speed limit of 30 kph was predominatly refered to by the value '30'. There were six more differenz kind of values that obviously meant the same (DE:zone30, etc.). Althought there is a difference if it is a speedlimit of 30 or speed limit zone 30, but the maxspeed is same for both cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 ways_tags table: postcode\n",
    "\n",
    "My first guess was historical berlin postcodes, but an evaluation showed that the postcodes are correct polish postcodes for a a small town behind the border to germany. The correctly formated (five digit) postcodes are areas around Berlin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polish Postcodes:\n",
      "{'74-404', '74-500', '74-400', '69-113', '74-520', '74-510', '74-405', '66-470', '74-406', '74-407', '66-629', '69-100', '74-311', '74-505', '74-503'}\n"
     ]
    }
   ],
   "source": [
    "all_postcodes = [n[0] for n in c_dirty.execute(\"SELECT value FROM ways_tags WHERE key = 'postcode'\")]\n",
    "print('Polish Postcodes:')\n",
    "print(set([x for x in all_postcodes if len(x) == 6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Inconsistent Key Formating\n",
    "\n",
    "The key row in the nodes_tags table and ways_tags table was harmonized by turning all key into lower character strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statement = \"\"\"SELECT * FROM nodes_tags\"\"\"\n",
    "data = [n for n in c_dirty.execute(statement).fetchall() if not n[1].islower()]\n",
    "\n",
    "for n in data:\n",
    "    statem = \"UPDATE nodes_tags SET key = '{key}' WHERE id = {id_}\".format(key=n[1].lower(), id_=n[0])\n",
    "    c_clean.execute(statem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for p in [n for n in c_dirty.execute(\"SELECT * FROM ways_tags\").fetchall() if not n[1].islower()]:\n",
    "    statement = \"\"\"UPDATE ways_tags SET key = '{key}' WHERE id = {id_}\"\"\".format(key=n[1].lower(), id_=n[0])\n",
    "    c_clean.execute(statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ways_tags maxspeed\n",
    "\n",
    "The maxspeed key values in the table were cleaned in the following way: All maxspeed values greater than 140 were changed to 'no limit'. All other values that contained also literals and the numbers '30' were changed to 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in [n for n in c_dirty.execute(\"SELECT * FROM ways_tags WHERE key = 'maxspeed'\").fetchall()]:\n",
    "    if n[2].isnumeric():\n",
    "        if int(n[2]) > 140:\n",
    "            c_clean.execute(\"UPDATE ways_tags SET value = 'no limit' WHERE id = {}\".format(n[0]))\n",
    "        else:\n",
    "            continue\n",
    "    elif '30' in n[2]:\n",
    "        c_clean.execute(\"\"\"UPDATE ways_tags SET value = '30' WHERE id = {}\"\"\".format(n[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('50', 73199)\n"
     ]
    }
   ],
   "source": [
    "for n in c_clean.execute(\"SELECT value, Count(*) FROM ways_tags WHERE key = 'maxspeed' ORDER BY Count(*) DESC LIMIT 15;\").fetchall():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 postcode - reducing area to Berlin City\n",
    "\n",
    "All rows in the ways_tags table that contained a longer than 5 digits postcode were removed. If the the postcode was a valid german postcode (5 digit) it was removed, if it wasn't between 10115 and 14199. \n",
    "\n",
    "In a cascade the corresponding rows in ways were removed as well.\n",
    "\n",
    "The same ways applied to the nodes_tags and nodes table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_ids = [n for n in c_dirty.execute(\"SELECT id, value FROM ways_tags WHERE key = 'postcode'\").fetchall()]\n",
    "\n",
    "ids_to_remove = []\n",
    "for id_, plz in all_ids:\n",
    "    if len(plz) > 5:\n",
    "        ids_to_remove.append(id_)\n",
    "    elif plz.isnumeric():\n",
    "        if int(plz) < 10115 or int(plz) > 14199:\n",
    "            ids_to_remove.append(id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, id_ in enumerate(ids_to_remove):\n",
    "    c_clean.execute(\"DELETE FROM ways_tags WHERE id = {}\".format(id_))\n",
    "    c_clean.execute(\"DELETE FROM ways WHERE id = {}\".format(id_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_ids = [n for n in c_dirty.execute(\"SELECT id, value FROM nodes_tags WHERE key = 'postcode'\").fetchall()]\n",
    "\n",
    "ids_to_remove = []\n",
    "for id_, plz in all_ids:\n",
    "    if len(plz) > 5:\n",
    "        ids_to_remove.append(id_)\n",
    "    elif plz.isnumeric():\n",
    "        if int(plz) < 10115 or int(plz) > 14199:\n",
    "            ids_to_remove.append(id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d20255ab530e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids_to_remove\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mc_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DELETE FROM nodes_tags WHERE id = {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mc_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DELETE FROM nodes WHERE id = {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, id_ in enumerate(ids_to_remove):\n",
    "    c_clean.execute(\"DELETE FROM nodes_tags WHERE id = {}\".format(id_))\n",
    "    c_clean.execute(\"DELETE FROM nodes WHERE id = {}\".format(id_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the contributors\n",
    "\n",
    "### Number of unique contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,870\n"
     ]
    }
   ],
   "source": [
    "print(formatnum(c_clean.execute(\"SELECT Count(*) FROM (SELECT uid FROM nodes UNION SELECT uid FROM ways) tmp;\").fetchall()[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 15 contributors by count\n",
    "\n",
    "The top 15 constributors each amass considerable rate of above 100,000 each. The top contributor has over 2.378 Mil. Any amount like this can only achieved programaticaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "SELECT user, COUNT(*) FROM nodes\n",
    "  GROUP BY user\n",
    "UNION ALL\n",
    "SELECT user, COUNT(*) FROM ways\n",
    "  GROUP BY user\n",
    "ORDER BY COUNT(*) DESC\n",
    "LIMIT 15;\n",
    "\"\"\"\n",
    "\n",
    "for n in c_clean.execute(statement).fetchall():\n",
    "    nr = \"{:,}\".format(n[1])\n",
    "    print(n[0], \" \" * (20 - len(n[0])), \" \" * (9 - len(nr)), nr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 15 contributor by duration of contribution\n",
    "\n",
    "Quite a lot of contributors contributet over a longer timeframe. The top list might not be accurate, since old changeset are not included, but an estimation shows many users who made contributions who are many years apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "SELECT user, timestamp \n",
    "FROM nodes\n",
    "UNION\n",
    "SELECT user, timestamp\n",
    "FROM ways\n",
    "\"\"\"\n",
    "users_w_time = [[n[0], time_from_timestamp(n[1])] for n in c_clean.execute(statement).fetchall()]\n",
    "\n",
    "users = defaultdict(list)\n",
    "\n",
    "for name, time in users_w_time:\n",
    "    users[name] += [time]\n",
    "\n",
    "users_result = []\n",
    "\n",
    "for name, time_list in users.items():\n",
    "    users_result.append([name, max(time_list), min(time_list), max(time_list) - min(time_list)])\n",
    "\n",
    "users_results_sorted = sorted(users_result, key = lambda x: x[3], reverse=True)[:15]\n",
    "\n",
    "for n in users_results_sorted:\n",
    "    print(\"Username:\", n[0], \" \" * (18 - len(n[0])) , \"aktive: \", n[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Additional Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Top 15 Amenity\n",
    "\n",
    "Of the top 15 most were expected. I didn't expect 2,011 hunting stands but the data captures quite a bit of the rural areas around downtown Berlin. Still: More hunting stands than kindergardens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "SELECT value, Count(*)\n",
    "FROM nodes_tags\n",
    "WHERE key = 'amenity'\n",
    "GROUP BY value\n",
    "ORDER BY Count(*) DESC\n",
    "LIMIT 15;\n",
    "\"\"\"\n",
    "\n",
    "for n in c_clean.execute(statement).fetchall():\n",
    "    print(n[0], \" \" * (15 - len(n[0])), formatnum(n[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster of italian places\n",
    "\n",
    "All italian restaurants were plottet to see clusters. There is a fair amoun places of places (ca. 800). The divide between west and east is still visible. The more detailed map shows in which areas there are more. \n",
    "\n",
    "Italian restaurants dominate in the old western part in Charlottenburg in Wilmersdorf, the important and more well of areas before the fall of the wall. \n",
    "\n",
    "In the eastern part there are a lot of places in the well-off parts like Mitte, Prenzlauer Berg and Friedrichshein. The areas in the north of the city center (Wedding, Pankow, Moabit, etc.) and in the south (Neuk√∂lln) have fewer italian places. The places with fewer places are those were more immigrants live, so italian food might be more a thing for the people without and immigrational background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statement = \"\"\"\n",
    "SELECT nodes.lon, nodes.lat\n",
    "FROM nodes_tags\n",
    "JOIN nodes ON nodes.id = nodes_tags.id\n",
    "WHERE nodes_tags.value = \"italian\"\n",
    "AND key = 'cuisine'\n",
    "\"\"\"\n",
    "\n",
    "italian_places = list(c_clean.execute(statement).fetchall())\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['lat'] = [n[1] for n in italian_places]\n",
    "df['lon'] = [n[0] for n in italian_places]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter([n[0] for n in italian_places], [n[1] for n in italian_places])\n",
    "plt.title('Mapping of Italian Restaurants in Berlin')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The following map was created with the script italian_places.py\n",
    "![title](italian_cluster.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas for Improvement\n",
    "\n",
    "The data for Berlin is generally on a high level. Common standards are partly missing for values like maxspeed on ways. It should be possible to work on this in a programmatical way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Berlin is big and cleaning up all the \\\"fixme\\\" and other open ends is a lifetime job. The data is generally considering the size quite good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
